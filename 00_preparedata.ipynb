{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation.\n",
        "\n",
        "Licensed under the MIT License.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DISCLAIMER\n",
        "By accessing this code, you acknowledge that the code is not designed, intended, or made available: (1) as a medical device(s); (2) for the diagnosis of disease or other conditions, or in the cure, mitigation, treatment or prevention of a disease or other conditions; or (3) as a substitute for professional medical advice, diagnosis, treatment, or judgment. Do not use this code to replace, substitute, or provide professional medical advice, diagnosis, treatment, or judgement. You are solely responsible for ensuring the regulatory, legal, and/or contractual compliance of any use of the code, including obtaining any authorizations or consents, and any solution you choose to build that incorporates this code in whole or in part.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clean Data\n",
        "We are using an open source Diabetes dataset from . The first step is to clean the source dataset into a version we can work with:\n",
        "\n",
        "* Replace missing values with \"NaNSpec\"\n",
        "* Feature engineering\n",
        "* Write the results to the data lake\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Library Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Read in Data from Azure Data Lake\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "data_lake_account_name = ''\n",
        "file_system_name = 'raw'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set raw data schema \n",
        "rawSchema = StructType([StructField(\"encounter_id\", StringType(), True), \n",
        "                    StructField(\"patient_nbr\", StringType(), True), \n",
        "                    StructField(\"race\", StringType(), True) , \n",
        "                    StructField(\"gender\", StringType(), True), \n",
        "                    StructField(\"age\", StringType(), True), \n",
        "                    StructField(\"weight\", StringType(), True), \n",
        "                    StructField(\"admission_type_id\", StringType(), True), \n",
        "                    StructField(\"discharge_disposition_id\", StringType(), True), \n",
        "                    StructField(\"admission_source_id\", StringType(), True), \n",
        "                    StructField(\"time_in_hospital\", StringType(), True),\n",
        "                    StructField(\"payer_code\", StringType(), True), \n",
        "                    StructField(\"medical_specialty\", StringType(), True), \n",
        "                    StructField(\"num_lab_procedures\", StringType(), True), \n",
        "                    StructField(\"num_procedures\", StringType(), True), \n",
        "                    StructField(\"num_medications\", StringType(), True), \n",
        "                    StructField(\"number_outpatient\", StringType(), True), \n",
        "                    StructField(\"number_emergency\", StringType(), True), \n",
        "                    StructField(\"number_inpatient\", StringType(), True), \n",
        "                    StructField(\"diag_1\", StringType(), True), \n",
        "                    StructField(\"diag_2\", StringType(), True),\n",
        "                    StructField(\"diag_3\", StringType(), True), \n",
        "                    StructField(\"number_diagnoses\", StringType(), True), \n",
        "                    StructField(\"max_glu_serum\", StringType(), True), \n",
        "                    StructField(\"A1Cresult\", StringType(), True), \n",
        "                    StructField(\"metformin\", StringType(), True), \n",
        "                    StructField(\"repaglinide\", StringType(), True), \n",
        "                    StructField(\"nateglinide\", StringType(), True), \n",
        "                    StructField(\"chlorpropamide\", StringType(), True),\n",
        "                    StructField(\"glimepiride\", StringType(), True), \n",
        "                    StructField(\"acetohexamide\", StringType(), True), \n",
        "                    StructField(\"glipizide\", StringType(), True), \n",
        "                    StructField(\"glyburide\", StringType(), True), \n",
        "                    StructField(\"tolbutamide\", StringType(), True), \n",
        "                    StructField(\"pioglitazone\", StringType(), True), \n",
        "                    StructField(\"rosiglitazone\", StringType(), True),\n",
        "                    StructField(\"acarbose\", StringType(), True), \n",
        "                    StructField(\"miglitol\", StringType(), True), \n",
        "                    StructField(\"troglitazone\", StringType(), True), \n",
        "                    StructField(\"tolazamide\", StringType(), True), \n",
        "                    StructField(\"examide\", StringType(), True), \n",
        "                    StructField(\"citoglipton\", StringType(), True), \n",
        "                    StructField(\"insulin\", StringType(), True), \n",
        "                    StructField(\"glyburide-metformin\", StringType(), True),  \n",
        "                    StructField(\"glipizide-metformin\", StringType(), True), \n",
        "                    StructField(\"glimepiride-pioglitazone\", StringType(), True), \n",
        "                    StructField(\"metformin-rosiglitazone\", StringType(), True), \n",
        "                    StructField(\"metformin-pioglitazone\", StringType(), True), \n",
        "                    StructField(\"change\", StringType(), True),  \n",
        "                    StructField(\"diabetesMed\", StringType(), True),\n",
        "                    StructField(\"readmitted\", StringType(), True), \n",
        "                    StructField(\"FirstName\", StringType(), True), \n",
        "                    StructField(\"LastName\", StringType(), True),\n",
        "                    StructField(\"Id\", StringType(), True)\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# set transformed data schema\n",
        "transformedSchema = StructType([StructField(\"race\", StringType(), True), \n",
        "                    StructField(\"gender\", StringType(), True), \n",
        "                    StructField(\"age\", StringType(), True) , \n",
        "                    StructField(\"admission_type_id\", StringType(), True), \n",
        "                    StructField(\"discharge_disposition_id\", StringType(), True), \n",
        "                    StructField(\"admission_source_id\", StringType(), True), \n",
        "                    StructField(\"time_in_hospital\", StringType(), True), \n",
        "                    StructField(\"payer_code\", StringType(), True), \n",
        "                    StructField(\"num_lab_procedures\", StringType(), True), \n",
        "                    StructField(\"num_procedures\", StringType(), True), \n",
        "                    StructField(\"num_medications\", StringType(), True),\n",
        "                    StructField(\"number_outpatient\", StringType(), True), \n",
        "                    StructField(\"number_emergency\", StringType(), True), \n",
        "                    StructField(\"number_inpatient\", StringType(), True), \n",
        "                    StructField(\"number_diagnoses\", StringType(), True), \n",
        "                    StructField(\"max_glu_serum\", StringType(), True), \n",
        "                    StructField(\"A1Cresult\", StringType(), True), \n",
        "                    StructField(\"metformin\", StringType(), True), \n",
        "                    StructField(\"repaglinide\", StringType(), True), \n",
        "                    StructField(\"nateglinide\", StringType(), True), \n",
        "                    StructField(\"chlorpropamide\", StringType(), True), \n",
        "                    StructField(\"glimepiride\", StringType(), True),\n",
        "                    StructField(\"glipizide\", StringType(), True), \n",
        "                    StructField(\"glyburide\", StringType(), True), \n",
        "                    StructField(\"tolbutamide\", StringType(), True), \n",
        "                    StructField(\"pioglitazone\", StringType(), True), \n",
        "                    StructField(\"rosiglitazone\", StringType(), True), \n",
        "                    StructField(\"acarbose\", StringType(), True), \n",
        "                    StructField(\"miglitol\", StringType(), True), \n",
        "                    StructField(\"tolazamide\", StringType(), True),\n",
        "                    StructField(\"insulin\", StringType(), True), \n",
        "                    StructField(\"glyburide-metformin\", StringType(), True), \n",
        "                    StructField(\"metformin-rosiglitazone\", StringType(), True), \n",
        "                    StructField(\"change\", StringType(), True), \n",
        "                    StructField(\"diabetesMed\", StringType(), True), \n",
        "                    StructField(\"FirstName\", StringType(), True), \n",
        "                    StructField(\"LastName\", StringType(), True),\n",
        "                    StructField(\"Id\", StringType(), True), \n",
        "                    StructField(\"spec_InternalMedicine\", BooleanType(), True), \n",
        "                    StructField(\"spec_Emergency/Trauma\", BooleanType(), True),\n",
        "                    StructField(\"spec_Family/GeneralPractice\", BooleanType(), True), \n",
        "                    StructField(\"spec_Cardiology\", BooleanType(), True), \n",
        "                    StructField(\"spec_Surgery-General\", BooleanType(), True), \n",
        "                    StructField(\"diag_428\", BooleanType(), True), \n",
        "                    StructField(\"diag_250\", BooleanType(), True), \n",
        "                    StructField(\"diag_276\", BooleanType(), True), \n",
        "                    StructField(\"diag_414\", BooleanType(), True), \n",
        "                    StructField(\"diag_401\", BooleanType(), True),  \n",
        "                    StructField(\"diag_427\", BooleanType(), True), \n",
        "                    StructField(\"diag_599\", BooleanType(), True), \n",
        "                    StructField(\"diag_496\", BooleanType(), True), \n",
        "                    StructField(\"diag_403\", BooleanType(), True), \n",
        "                    StructField(\"diag_486\", BooleanType(), True),  \n",
        "                    StructField(\"is_readmitted\", BooleanType(), True)\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Raw Data from ADLS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "diagram": {
          "activateDiagramType": 1,
          "chartConfig": {
            "aggByBackend": false,
            "aggregation": "COUNT",
            "category": "bar",
            "keys": [
              "patient_nbr"
            ],
            "values": [
              "patient_nbr"
            ],
            "xLabel": "patient_nbr",
            "yLabel": "patient_nbr"
          },
          "isSql": false,
          "isSummary": false,
          "previewData": {
            "filter": null
          }
        }
      },
      "outputs": [],
      "source": [
        "df_raw = spark.read.format(\"csv\").load(f\"abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/DatasetDiabetes/diabetic_data.csv\",header=True,multiLine=True)\n",
        "df_names = spark.read.format(\"csv\").load(f\"abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/Names/Names.csv\",header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generateNamesMale (df_raw, df_names):\n",
        "    df_raw_m = df_raw.filter(col('gender') == \"Male\")\n",
        "    df_names_m = df_names.filter(col('gender') == \"Male\")\n",
        "\n",
        "    df_names_m = df_names_m.toPandas()\n",
        "    df_raw_m = df_raw_m.toPandas()\n",
        "\n",
        "    df_names_m = pd.DataFrame(df_names_m.values.repeat(df_raw_m.shape[0]/df_names_m.shape[0] +1,  axis=0), columns=df_names_m.columns)\n",
        "    df_names_m = df_names_m.head(df_raw_m.shape[0])\n",
        "    df_names_m = df_names_m.sample(frac= 1)\n",
        "\n",
        "    df_male = df_raw_m.join(df_names_m[['FirstName', 'LastName']])\n",
        "    df_sp_male = spark.createDataFrame(df_male)\n",
        "    return df_sp_male"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generateNamesFemale(df_raw, df_names):\n",
        "    df_raw_f = df_raw.filter(col('gender') == \"Female\")\n",
        "    df_names_f = df_names.filter(col('gender') == \"Female\")\n",
        "\n",
        "    df_names_f = df_names_f.toPandas()\n",
        "    df_raw_f = df_raw_f.toPandas()\n",
        "\n",
        "    df_names_f = pd.DataFrame(df_names_f.values.repeat(df_raw_f.shape[0]/df_names_f.shape[0] +1,  axis=0), columns=df_names_f.columns)\n",
        "    df_names_f = df_names_f.head(df_raw_f.shape[0])\n",
        "    df_names_f = df_names_f.sample(frac= 1)\n",
        "\n",
        "    df_female = df_raw_f.join(df_names_f[['FirstName', 'LastName']])\n",
        "    df_sp_female = spark.createDataFrame(df_female)\n",
        "    return df_sp_female"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "diagram": {
          "activateDiagramType": 1,
          "chartConfig": {
            "aggByBackend": false,
            "aggregation": "COUNT",
            "category": "bar",
            "keys": [
              "encounter_id"
            ],
            "values": [
              "encounter_id"
            ],
            "xLabel": "encounter_id",
            "yLabel": "encounter_id"
          },
          "isSql": false,
          "isSummary": false,
          "previewData": {
            "filter": null
          }
        }
      },
      "outputs": [],
      "source": [
        "df_male = generateNamesMale(df_raw, df_names)\n",
        "df_female = generateNamesFemale(df_raw, df_names)\n",
        "\n",
        "df = df_male.union(df_female)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "diagram": {
          "activateDiagramType": 1,
          "chartConfig": {
            "aggByBackend": false,
            "aggregation": "SUM",
            "category": "bar",
            "keys": [
              "patient_nbr"
            ],
            "values": [
              "patientId"
            ],
            "xLabel": "patient_nbr",
            "yLabel": "patientId"
          },
          "isSql": false,
          "isSummary": false,
          "previewData": {
            "filter": null
          }
        }
      },
      "outputs": [],
      "source": [
        "df = df.toPandas()\n",
        "\n",
        "df.loc[:,'Id'] = pd.factorize(df['patient_nbr'])[0]\n",
        "df_sp = spark.createDataFrame(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sp.write.option('header', 'true').mode('overwrite').csv(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/DatasetDiabetes/prepareddata/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def create_additional_features(df): \n",
        "    to_drop = ['acetohexamide', 'troglitazone', 'examide', 'citoglipton',\n",
        "           'glipizide-metformin', 'glimepiride-pioglitazone',\n",
        "           'metformin-pioglitazone', 'weight', 'patient_nbr', 'encounter_id']\n",
        "    df.drop(to_drop, axis=1, inplace=True, errors = 'ignore')\n",
        "    df_transformed = df.replace('?', np.nan) \n",
        "    #print(df_transformed.shape)\n",
        "\n",
        "    spec_counts_raw = {\"specs\": ['InternalMedicine', 'Emergency/Trauma', 'Family/GeneralPractice','Cardiology',\n",
        "                       'Surgery-General'], \"num patients\": [14635,  7565,  7440,  5352,  3099]}\n",
        "\n",
        "    df_transformed['medical_specialty'] = df_transformed['medical_specialty'].replace(np.nan, \"NaNSpec\")\n",
        "    spec_counts = pd.DataFrame(data = spec_counts_raw)\n",
        "    spec_thresh = 5\n",
        "    for (index, row) in spec_counts.head(spec_thresh).iterrows():\n",
        "        spec = row['specs']\n",
        "        new_col = 'spec_' + str(spec)\n",
        "        df_transformed[new_col] = (df_transformed.medical_specialty == spec)\n",
        "    #print(df_transformed.shape)\n",
        "\n",
        "    diag_counts_raw = {\"icd9value\": ['428', '250', '276', '414', '401', '427', '599', '496', '403', '486'],\n",
        "                    'num patients w diag': [18101., 17861., 13816., 12895., 12371., 11757.,  6824.,  5990.,5693., 5455.]}\n",
        "\n",
        "    diag_counts = pd.DataFrame(diag_counts_raw, columns = [ 'icd9value', 'num patients w diag'])\n",
        "\n",
        "    diag_thresh = 10\n",
        "    for (index, row) in diag_counts.head(diag_thresh).iterrows():\n",
        "        icd9 = row['icd9value']\n",
        "        new_col = 'diag_' + str(icd9)\n",
        "        df_transformed[new_col] = (df_transformed.diag_1 == icd9)|(df_transformed.diag_2 == icd9)|(df_transformed.diag_3 == icd9)\n",
        "    \n",
        "    #print(df_transformed.columns)\n",
        "\n",
        "    df_transformed = df_transformed.reset_index(drop=True)\n",
        "\n",
        "    df_transformed2 = pd.DataFrame(df_transformed, copy=True) #preserve df_transformed so I can rerun this step\n",
        "    df_transformed2['age'] = df_transformed2.age.str.extract('(\\d+)-\\d+')\n",
        "\n",
        "    to_drop = ['acetohexamide', 'troglitazone', 'examide', 'citoglipton',\n",
        "        'glipizide-metformin', 'glimepiride-pioglitazone',\n",
        "        'metformin-pioglitazone', 'weight', 'medical_specialty', 'diag_2',\n",
        "        'diag_1', 'diag_3', 'patient_nbr', 'encounter_id']\n",
        "    df_transformed2.drop(to_drop, axis=1, inplace=True,errors = 'ignore')\n",
        "    #print(df_transformed2.shape)\n",
        "\n",
        "    df_transformed2 = df_transformed2.reset_index(drop=True)\n",
        "\n",
        "    print(df_transformed2['readmitted'].value_counts())\n",
        "\n",
        "    #create outcome variable\n",
        "    df_transformed2['is_readmitted'] = (df_transformed2.readmitted != 'NO')  #check why this is happening\n",
        "    df_transformed2.drop('readmitted', axis=1, inplace=True)\n",
        "\n",
        "    df = pd.DataFrame(df_transformed2)\n",
        "\n",
        "    #partition training and test data, one balanced training set, all remaining for testing \n",
        "    outcome_column = 'is_readmitted' \n",
        "\n",
        "    #Imputing with outlying value since we are focusing on tree based methods\n",
        "    df = df.fillna(-9999) \n",
        "\n",
        "    df = df.reset_index(drop=True)\n",
        "    df.dtypes\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train-Test Split\n",
        "\n",
        "Split data into a 50-50 training-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read in raw data \n",
        "df = spark.read.format(\"csv\").load(f\"abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/DatasetDiabetes/prepareddata/\",header=True,multiLine=True)\n",
        "df_raw = df.toPandas()\n",
        "\n",
        "df_raw.rename(columns = {'readmitted\\r':'readmitted'}, inplace = True)\n",
        "\n",
        "#save dataset \n",
        "df_sp = spark.createDataFrame(df_raw,schema=rawSchema)\n",
        "df_sp.write.option('header', 'true').mode('overwrite').csv(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/DatasetDiabetes/prepareddata/')\n",
        "\n",
        "df_sp.write.format(\"cosmos.oltp\")\\\n",
        "    .option(\"spark.synapse.linkedService\", \"patientHubDB\")\\\n",
        "    .option(\"spark.cosmos.container\", \"Patient\")\\\n",
        "    .option(\"spark.cosmos.write.upsertEnabled\", \"true\")\\\n",
        "    .mode('overwrite')\\\n",
        "    .save()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df_raw, test_size=0.5)\n",
        "\n",
        "# save test df \n",
        "test_sp = spark.createDataFrame(test,schema=rawSchema)\n",
        "test_sp.write.option('header', 'true').mode('overwrite').csv(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/DatasetDiabetes/preparedtestdata/')\n",
        "\n",
        "df = create_additional_features(train)\n",
        "\n",
        "# save train df \n",
        "train_sp = spark.createDataFrame(df,schema=transformedSchema)\n",
        "train_sp.write.option('header', 'true').mode('overwrite').csv(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/DatasetDiabetes/preparedtraindata/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save Prepared Data to Spark Table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#load the cleaned data to a spark database \n",
        "try:\n",
        "   spark.sql(\"CREATE DATABASE diabetesdb\")\n",
        "except:\n",
        "   print(\"Database already exists\")\n",
        "train_sp.write.mode(\"overwrite\").saveAsTable(\"diabetesdb.traindata\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "try:\n",
        "   spark.sql(\"CREATE DATABASE diabetesdb\")\n",
        "except:\n",
        "   print(\"Database already exists\")\n",
        "test_sp.write.mode(\"overwrite\").saveAsTable(\"diabetesdb.testdata\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": false,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
