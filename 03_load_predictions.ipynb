{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation. \n",
        "\n",
        "Licensed under the MIT license."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DISCLAIMER\n",
        "By accessing this code, you acknowledge that the code is not designed, intended, or made available: (1) as a medical device(s); (2) for the diagnosis of disease or other conditions, or in the cure, mitigation, treatment or prevention of a disease or other conditions; or (3) as a substitute for professional medical advice, diagnosis, treatment, or judgment. Do not use this code to replace, substitute, or provide professional medical advice, diagnosis, treatment, or judgement. You are solely responsible for ensuring the regulatory, legal, and/or contractual compliance of any use of the code, including obtaining any authorizations or consents, and any solution you choose to build that incorporates this code in whole or in part.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data_lake_account_name = ''\n",
        "file_system_name = 'raw'\n",
        "\n",
        "# aml workspace config\n",
        "subscription_id = \"\" \n",
        "resource_group = \"\" \n",
        "workspace_name = \"\" \n",
        "workspace_region = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "cosmosSchema = StructType([StructField(\"Id\", StringType(), True), \n",
        "                    StructField(\"patient_nbr\", StringType(), True), \n",
        "                    StructField(\"FirstName\", StringType(), True), \n",
        "                    StructField(\"LastName\", StringType(), True), \n",
        "                    StructField(\"race\", StringType(), True) , \n",
        "                    StructField(\"gender\", StringType(), True), \n",
        "                    StructField(\"age\", StringType(), True), \n",
        "                    StructField(\"weight\", StringType(), True), \n",
        "                    StructField(\"admission_type_id\", StringType(), True), \n",
        "                    StructField(\"discharge_disposition_id\", StringType(), True), \n",
        "                    StructField(\"admission_source_id\", StringType(), True), \n",
        "                    StructField(\"time_in_hospital\", StringType(), True),\n",
        "                    StructField(\"payer_code\", StringType(), True), \n",
        "                    StructField(\"medical_specialty\", StringType(), True), \n",
        "                    StructField(\"num_lab_procedures\", StringType(), True), \n",
        "                    StructField(\"num_procedures\", StringType(), True), \n",
        "                    StructField(\"num_medications\", StringType(), True), \n",
        "                    StructField(\"number_outpatient\", StringType(), True), \n",
        "                    StructField(\"number_emergency\", StringType(), True), \n",
        "                    StructField(\"number_inpatient\", StringType(), True), \n",
        "                    StructField(\"diag_1\", StringType(), True), \n",
        "                    StructField(\"diag_2\", StringType(), True),\n",
        "                    StructField(\"diag_3\", StringType(), True), \n",
        "                    StructField(\"number_diagnoses\", StringType(), True), \n",
        "                    StructField(\"max_glu_serum\", StringType(), True), \n",
        "                    StructField(\"A1Cresult\", StringType(), True), \n",
        "                    StructField(\"metformin\", StringType(), True), \n",
        "                    StructField(\"repaglinide\", StringType(), True), \n",
        "                    StructField(\"nateglinide\", StringType(), True), \n",
        "                    StructField(\"chlorpropamide\", StringType(), True),\n",
        "                    StructField(\"glimepiride\", StringType(), True), \n",
        "                    StructField(\"acetohexamide\", StringType(), True), \n",
        "                    StructField(\"glipizide\", StringType(), True), \n",
        "                    StructField(\"glyburide\", StringType(), True), \n",
        "                    StructField(\"tolbutamide\", StringType(), True), \n",
        "                    StructField(\"pioglitazone\", StringType(), True), \n",
        "                    StructField(\"rosiglitazone\", StringType(), True),\n",
        "                    StructField(\"acarbose\", StringType(), True), \n",
        "                    StructField(\"miglitol\", StringType(), True), \n",
        "                    StructField(\"troglitazone\", StringType(), True), \n",
        "                    StructField(\"tolazamide\", StringType(), True), \n",
        "                    StructField(\"examide\", StringType(), True), \n",
        "                    StructField(\"citoglipton\", StringType(), True), \n",
        "                    StructField(\"insulin\", StringType(), True), \n",
        "                    StructField(\"glyburide-metformin\", StringType(), True),  \n",
        "                    StructField(\"glipizide-metformin\", StringType(), True), \n",
        "                    StructField(\"glimepiride-pioglitazone\", StringType(), True), \n",
        "                    StructField(\"metformin-rosiglitazone\", StringType(), True), \n",
        "                    StructField(\"metformin-pioglitazone\", StringType(), True), \n",
        "                    StructField(\"change\", StringType(), True),  \n",
        "                    StructField(\"diabetesMed\", StringType(), True),\n",
        "                    StructField(\"readmitted\", StringType(), True)\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#save the model to a local file\n",
        "import azureml.core\n",
        "\n",
        "from azureml.core import Workspace\n",
        "ws = Workspace(workspace_name = workspace_name,\n",
        "               subscription_id = subscription_id,\n",
        "               resource_group = resource_group)\n",
        "ws.write_config()   \n",
        "\n",
        "from azureml.core.model import Model\n",
        "\n",
        "#from sklearn.externals import joblib\n",
        "import joblib\n",
        "model_name='diabetesmodel'\n",
        "model_path = Model.get_model_path(model_name=model_name, _workspace=ws)\n",
        "loaded_model = joblib.load(model_path)\n",
        "print('model loaded!')\n",
        "\n",
        "\n",
        "model_name='scoring_explainer.pkl'\n",
        "model_path = Model.get_model_path(model_name=model_name, _workspace=ws)\n",
        "scoring_explainer = joblib.load(model_path)\n",
        "print('model explainer loaded!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_additional_features(df): \n",
        "    to_drop = ['acetohexamide', 'troglitazone', 'examide', 'citoglipton',\n",
        "           'glipizide-metformin', 'glimepiride-pioglitazone',\n",
        "           'metformin-pioglitazone', 'weight', 'patient_nbr', 'encounter_id']\n",
        "    df.drop(to_drop, axis=1, inplace=True, errors = 'ignore')\n",
        "    df_transformed = df.replace('?', np.nan) \n",
        "    \n",
        "    spec_counts_raw = {\"specs\": ['InternalMedicine', 'Emergency/Trauma', 'Family/GeneralPractice','Cardiology',\n",
        "                       'Surgery-General'], \"num patients\": [14635,  7565,  7440,  5352,  3099]}\n",
        "\n",
        "    df_transformed['medical_specialty'] = df_transformed['medical_specialty'].replace(np.nan, \"NaNSpec\")\n",
        "    spec_counts = pd.DataFrame(data = spec_counts_raw)\n",
        "    spec_thresh = 5\n",
        "    for (index, row) in spec_counts.head(spec_thresh).iterrows():\n",
        "        spec = row['specs']\n",
        "        new_col = 'spec_' + str(spec)\n",
        "        df_transformed[new_col] = (df_transformed.medical_specialty == spec)\n",
        "\n",
        "    diag_counts_raw = {\"icd9value\": ['428', '250', '276', '414', '401', '427', '599', '496', '403', '486'],\n",
        "                    'num patients w diag': [18101., 17861., 13816., 12895., 12371., 11757.,  6824.,  5990.,5693., 5455.]}\n",
        "\n",
        "    diag_counts = pd.DataFrame(diag_counts_raw, columns = [ 'icd9value', 'num patients w diag'])\n",
        "\n",
        "    diag_thresh = 10\n",
        "    for (index, row) in diag_counts.head(diag_thresh).iterrows():\n",
        "        icd9 = row['icd9value']\n",
        "        new_col = 'diag_' + str(icd9)\n",
        "        df_transformed[new_col] = (df_transformed.diag_1 == icd9)|(df_transformed.diag_2 == icd9)|(df_transformed.diag_3 == icd9)\n",
        "\n",
        "    df_transformed = df_transformed.reset_index(drop=True)\n",
        "\n",
        "    df_transformed2 = pd.DataFrame(df_transformed, copy=True) #preserve df_transformed so I can rerun this step\n",
        "    df_transformed2['age'] = df_transformed2.age.str.extract('(\\d+)-\\d+')\n",
        "\n",
        "    to_drop = ['acetohexamide', 'troglitazone', 'examide', 'citoglipton',\n",
        "        'glipizide-metformin', 'glimepiride-pioglitazone',\n",
        "        'metformin-pioglitazone', 'weight', 'medical_specialty', 'diag_2',\n",
        "        'diag_1', 'diag_3', 'patient_nbr', 'encounter_id']\n",
        "    df_transformed2.drop(to_drop, axis=1, inplace=True,errors = 'ignore')\n",
        "\n",
        "    df_transformed2 = df_transformed2.reset_index(drop=True)\n",
        "\n",
        "    #df_transformed2['readmitted'].value_counts()\n",
        "\n",
        "    df = pd.DataFrame(df_transformed2)\n",
        "\n",
        "    #Imputing with outlying value since we are focusing on tree based methods\n",
        "    df = df.fillna(-9999) \n",
        "\n",
        "    df = df.reset_index(drop=True)\n",
        "    df.dtypes\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "diagram": {
          "activateDiagramType": 1,
          "chartConfig": {
            "aggByBackend": false,
            "aggregation": "SUM",
            "category": "bar",
            "keys": [
              "patientId"
            ],
            "values": [
              "Score"
            ],
            "xLabel": "patientId",
            "yLabel": "Score"
          },
          "isSql": false,
          "isSummary": false,
          "previewData": {
            "filter": null
          }
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from azureml.train.automl.runtime.automl_explain_utilities import automl_setup_model_explanations\n",
        "\n",
        "#read in from cosmos \n",
        "df_test = spark.read.format(\"cosmos.oltp\")\\\n",
        "    .option(\"spark.synapse.linkedService\", \"patientHubDB\")\\\n",
        "    .option(\"spark.cosmos.container\", \"Patient\")\\\n",
        "    .load(schema=cosmosSchema)\n",
        "\n",
        "df_test = df_test.toPandas()\n",
        "\n",
        "#get the test data and drop output column\n",
        "outcome_column = 'readmitted'\n",
        "df_test = df_test.drop(outcome_column,axis=1)\n",
        "\n",
        "#df_test = df_test.head(10)\n",
        "df_test = create_additional_features(df_test)\n",
        "\n",
        "# drop Id column\n",
        "data_df = df_test  #.head(10)\n",
        "id_column = 'Id'\n",
        "data_df = data_df.drop(id_column,axis=1)\n",
        "\n",
        "#get predictions\n",
        "df_predictions = pd.DataFrame(loaded_model.predict_proba(data_df))\n",
        "df_predictions.columns = ['False','True']\n",
        "\n",
        "df_predictions = df_predictions[['True']]\n",
        "df_predictions['patientId'] = df_test['Id']\n",
        "df_predictions.columns = ['Prediction','patientId']\n",
        "df_predictions = df_predictions[['patientId','Prediction']]\n",
        "df_predictions_sp = spark.createDataFrame(df_predictions)  \n",
        "\n",
        "#display(df_predictions_sp)\n",
        "\n",
        "#write to ADLS and also save as spark table\n",
        "df_predictions_sp.write.option('header', 'true').mode('overwrite').csv(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/DatasetDiabetes/predictions/')\n",
        "# df_predictions_sp.write.mode(\"overwrite\").saveAsTable(\"default.diabetes_predictions\")\n",
        "\n",
        "#write predictions to CosmosDB\n",
        "df_predictions_sp.write.format(\"cosmos.oltp\")\\\n",
        "    .option(\"spark.synapse.linkedService\", \"patientHubDB\")\\\n",
        "    .option(\"spark.cosmos.container\", \"Predictions\")\\\n",
        "    .option(\"spark.cosmos.write.upsertEnabled\", \"true\")\\\n",
        "    .mode('overwrite')\\\n",
        "    .save()\n",
        "\n",
        "#get explanations and stack the results\n",
        "automl_explainer_setup_obj = automl_setup_model_explanations(loaded_model,X_test=data_df, task='classification')\n",
        "raw_local_importance_values = scoring_explainer.explain(automl_explainer_setup_obj.X_test_transform, get_raw=True)\n",
        "raw_local_importance_values\n",
        "\n",
        "df_exp = pd.DataFrame(raw_local_importance_values,columns=data_df.columns)\n",
        "df_exp['patientId'] = df_test['Id']\n",
        "df_exp.set_index(\"patientId\", inplace = True)\n",
        "df_exp\n",
        "df_exp_stacked = pd.DataFrame(df_exp.stack().reset_index())\n",
        "df_exp_stacked.columns = ['patientId','Feature','Score']\n",
        "df_exp_stacked\n",
        "\n",
        "df_exp_stacked_sp = spark.createDataFrame(df_exp_stacked) \n",
        "\n",
        "#display(df_exp_stacked_sp)\n",
        "\n",
        "#write to ADLS and also save as spark table\n",
        "df_exp_stacked_sp.write.option('header', 'true').mode('overwrite').csv(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/DatasetDiabetes/explanations/')\n",
        "# df_exp_stacked_sp.write.mode(\"overwrite\").saveAsTable(\"default.diabetes_explanations\")\n",
        "\n",
        "#write explanations to CosmosDB\n",
        "df_exp_stacked_sp.write.format(\"cosmos.oltp\")\\\n",
        "    .option(\"spark.synapse.linkedService\", \"patientHubDB\")\\\n",
        "    .option(\"spark.cosmos.container\", \"Explanations\")\\\n",
        "    .option(\"spark.cosmos.write.upsertEnabled\", \"true\")\\\n",
        "    .mode('overwrite')\\\n",
        "    .save()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": false,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
